{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using DOpt Federov Exchange Algorithm\n",
    "## Algorithm obtained from\n",
    "-  **Algorithm AS 295:** A Fedorov Exchange Algorithm for D-Optimal Design\n",
    "-  **Author(s):** Alan J. Miller and Nam-Ky Nguyen\n",
    "-  **Source:** Journal of the Royal Statistical Society. Series C (Applied Statistics), Vol. 43, No. 4, pp. 669-677, 1994\n",
    "-  **Stable URL:** http://www.jstor.org/stable/2986264\n",
    "\n",
    "## Source code from\n",
    "-  http://ftp.uni-bayreuth.de/math/statlib/apstat/\n",
    "\n",
    "## Notes\n",
    "- This is a two design variable, kwadratic model example problem from Myers and Montgomery, Response Surface Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dopt shared library that provides the interface\n",
    "\n",
    "### Print the documentation and note that\n",
    "### Input\n",
    "-  $x$ is the 2D numpy array that contains the candidate points to select from\n",
    "-  $n$ is the number of points in the final design\n",
    "-  $in$ is the number of preselected points that MUST be in the final design (>= 0)\n",
    "-  $rstart$ indicate if a random start should be performed, should be True in most cases.  If False the user must supply the initial design in $picked$\n",
    "-  $picked$ is a 1D array that contains the preselected point ID's (remember FORTRAN is 1 based array) on input.  The first $in$ entries are read for ID's.  On output it contains the ID's in x of the final selection\n",
    "\n",
    "### Output\n",
    "-  $lndet$ is the logarithm of the determinant of the best design\n",
    "-  $ifault$ is possible fault codes\n",
    ">-  -1 if no full rank starting design is found\n",
    ">-  0 if no error is detected\n",
    ">-  1* if DIM1 < NCAND\n",
    ">-  2* if K < N\n",
    ">-  4* if NRBAR < K(K - 1)/2\n",
    ">-  8* if K KIN + NBLOCK\n",
    ">-  16* if the sum of block sizes is not equal to N\n",
    ">-  32* if any IN(I) < 0 or any IN(I) > BLKSIZ(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lndet,ifault = dopt(x,n,in,rstart,picked)\n",
      "\n",
      "Wrapper for ``dopt``.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : input rank-2 array('d') with bounds (dim1,kin)\n",
      "n : input int\n",
      "in : input int\n",
      "rstart : input int\n",
      "picked : input rank-1 array('i') with bounds (n)\n",
      "\n",
      "Returns\n",
      "-------\n",
      "lndet : float\n",
      "ifault : int\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import math as m\n",
    "import dopt\n",
    "print( dopt.dopt.__doc__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the sample data set from the Excel spreadsheet and clean it up by removing all duplicate points\n",
    ">-  2 Design variables, Full Quadratic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Observation      z1     z2     x1     x2   y\n",
      "0            1  200.00  15.00 -1.000 -1.000  43\n",
      "1            2  250.00  15.00  1.000 -1.000  78\n",
      "2            3  200.00  25.00 -1.000  1.000  69\n",
      "3            4  250.00  25.00  1.000  1.000  73\n",
      "4            5  189.65  20.00 -1.414  0.000  48\n",
      "5            6  260.35  20.00  1.414  0.000  78\n",
      "6            7  225.00  12.93  0.000 -1.414  65\n",
      "7            8  225.00  27.07  0.000  1.414  74\n",
      "8            9  225.00  20.00  0.000  0.000  76\n",
      " \n",
      "[[ 1.         -0.70721358 -0.70721358  0.50015105  0.50015105  0.50015105]\n",
      " [ 1.          0.70721358 -0.70721358  0.50015105  0.50015105 -0.50015105]\n",
      " [ 1.         -0.70721358  0.70721358  0.50015105  0.50015105 -0.50015105]\n",
      " [ 1.          0.70721358  0.70721358  0.50015105  0.50015105  0.50015105]\n",
      " [ 1.         -1.          0.          1.          0.         -0.        ]\n",
      " [ 1.          1.          0.          1.          0.          0.        ]\n",
      " [ 1.          0.         -1.          0.          1.         -0.        ]\n",
      " [ 1.          0.          1.          0.          1.          0.        ]\n",
      " [ 1.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Sample data set from Excel spreadsheet\n",
    "filename = 'MyersExample.xlsx'\n",
    "xls = pd.ExcelFile(filename)\n",
    "df1 = pd.read_excel(xls, 'Sheet2')\n",
    "\n",
    "# Remove all duplicate rows from the data set - Note that the dataset now only have 8 unique values\n",
    "df1 = df1.drop_duplicates(subset=['x1','x2'], keep='first')\n",
    "print(df1)\n",
    "\n",
    "# Pull out the 3 and 4th columns as the x1 and x2 variables that we will use to create the model matrix from\n",
    "y  = df1.iloc[:, 5].values\n",
    "x1 = df1.iloc[:, 3].values\n",
    "x2 = df1.iloc[:, 4].values\n",
    "\n",
    "# Scale the variables - Seems to work if we scale or not - is typically always a good idea to scale\n",
    "x1 = (x1 + x1 - x1.min() - x1.max()) / (x1.max()-x1.min())\n",
    "x2 = (x2 + x2 - x2.min() - x2.max()) / (x2.max()-x2.min())\n",
    "\n",
    "# Setup the design matrix\n",
    "x = np.zeros((len(x1), 6), float)\n",
    "x[:,0] = 1.\n",
    "x[:,1] = x1\n",
    "x[:,2] = x2\n",
    "x[:,3] = x1*x1\n",
    "x[:,4] = x2*x2\n",
    "x[:,5] = x1*x2\n",
    "print(' ')\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the interface and print the output and the picked array\n",
    "-  We raise an exception with iFault is not 0 - this is just good practice\n",
    "-  We repeat the DOptimal process 10 times and pick the best design.  We do this in an attempt to avoid local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Determinant Found: 48.07337205914986\n",
      "\n",
      "Best Design Found (indices):\n",
      " [1 2 3 4 5 6 7 9]\n",
      "\n",
      "Best Design Found (variables):\n",
      " [[-0.70721358 -0.70721358  0.50015105]\n",
      " [ 0.70721358 -0.70721358  0.50015105]\n",
      " [-0.70721358  0.70721358  0.50015105]\n",
      " [ 0.70721358  0.70721358  0.50015105]\n",
      " [-1.          0.          1.        ]\n",
      " [ 1.          0.          1.        ]\n",
      " [ 0.         -1.          0.        ]\n",
      " [ 0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Number of points to pick - we can pick a max of 9 and a minimum of 6\n",
    "n = 8\n",
    "\n",
    "# Array of point ID's that will be picked\n",
    "picked = np.zeros( n, np.int32 )\n",
    "\n",
    "# Number of picked points (points to force into the design)\n",
    "npicked = 0\n",
    "\n",
    "# Store the best design and the corresponding determinant values\n",
    "bestDes = np.copy( picked )\n",
    "bestDet = 0\n",
    "rstart  = True   # Look at documentation for 295 - should not really need to change\n",
    "\n",
    "# Repeat the process 10 times and store the best design\n",
    "for i in range(0, 10) :\n",
    "    \n",
    "    # Make the DOptimal call\n",
    "    lnDet, iFault = dopt.dopt( x, n, npicked, rstart, picked)\n",
    "    \n",
    "    # Raise an exception if iFault is not equal to 0\n",
    "    if iFault != 0:\n",
    "        raise ValueError( \"Non-zero return code form dopt algorith.  iFault = \", iFault )\n",
    "       \n",
    "    # Store the best design\n",
    "    if m.fabs(lnDet) > bestDet:\n",
    "        bestDet =lnDet\n",
    "        bestDes = np.copy( picked )\n",
    "\n",
    "# Print the best design out\n",
    "print( \"Maximum Determinant Found:\", m.exp(bestDet) )\n",
    "print( \"\\nBest Design Found (indices):\\n\", np.sort(bestDes) )\n",
    "print( \"\\nBest Design Found (variables):\\n\", x[np.sort(bestDes)-1,1:4] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now solve the least squares problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.995\n",
      "Model:                            OLS   Adj. R-squared:                  0.982\n",
      "Method:                 Least Squares   F-statistic:                     78.49\n",
      "Date:                Tue, 03 Sep 2019   Prob (F-statistic):             0.0126\n",
      "Time:                        14:10:00   Log-Likelihood:                -10.575\n",
      "No. Observations:                   8   AIC:                             33.15\n",
      "Df Residuals:                       2   BIC:                             33.63\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         76.0008      1.815     41.871      0.001      68.191      83.811\n",
      "x1            14.3932      0.907     15.861      0.004      10.489      18.298\n",
      "x2             6.7706      1.171      5.780      0.029       1.730      11.811\n",
      "x3           -13.6538      2.160     -6.321      0.024     -22.949      -4.359\n",
      "x4            -5.5362      2.401     -2.306      0.148     -15.865       4.793\n",
      "x5           -15.4953      1.815     -8.539      0.013     -23.303      -7.688\n",
      "==============================================================================\n",
      "Omnibus:                        0.029   Durbin-Watson:                   1.256\n",
      "Prob(Omnibus):                  0.986   Jarque-Bera (JB):                0.261\n",
      "Skew:                           0.000   Prob(JB):                        0.878\n",
      "Kurtosis:                       2.115   Cond. No.                         6.09\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/scipy/stats/stats.py:1416: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "# Extract the DOptimum x and y values\n",
    "y_opt = y[np.sort(bestDes)-1]\n",
    "x_opt = x[np.sort(bestDes)-1]\n",
    "\n",
    "# Setup the Statsmodels model and perform the fit\n",
    "modOLS = sm.OLS( y_opt, x_opt )\n",
    "resOLS = modOLS.fit()\n",
    "\n",
    "# Print the summary of the ordinary least squares fit\n",
    "print( resOLS.summary() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
